{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDir = os.getcwd()\n",
    "rootDir = os.path.abspath(os.path.join(currDir,'..'))\n",
    "\n",
    "dataDir = os.path.abspath(os.path.join(rootDir,'data'))\n",
    "rawDataDir = os.path.abspath(os.path.join(dataDir,'raw'))\n",
    "interimDataDir = os.path.abspath(os.path.join(dataDir,'interim'))\n",
    "finalDataDir = os.path.abspath(os.path.join(dataDir,'final'))\n",
    "errorLog = os.path.abspath(os.path.join(dataDir,'error_log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read player bio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{rawDataDir}/all_NBA_ABA_players.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scraping player game logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#### BASIC STATS\n",
    "# https://www.basketball-reference.com/players/a/abdelal01.html\n",
    "# https://www.basketball-reference.com/players/a/abdelal01/gamelog/1992\n",
    "# https://www.basketball-reference.com/players/a/abdelal01/gamelog-playoffs/\n",
    "\n",
    "#### ADVANCED STATS\n",
    "# https://www.basketball-reference.com/players/a/abdelal01/gamelog-advanced/1992/\n",
    "# https://www.basketball-reference.com/players/a/abdelal01/gamelog-playoffs-advanced/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_reg_season_game_logs(player_idx,letter,from_year,to_year):\n",
    "    reg_season_game_logs = None\n",
    "    yearly_dfs = []\n",
    "    \n",
    "    # SCRAPING REGULAR SEASON GAMES\n",
    "    \n",
    "    for year in range(from_year, to_year+1):\n",
    "        url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog/{year}\"\n",
    "        webpage = urlopen(url)\n",
    "        html = BeautifulSoup(webpage)\n",
    "        tables = html.findAll('table')\n",
    "        '''\n",
    "        if len(tables) > 0:\n",
    "            table = str(tables[-1])\n",
    "            yearly_game_log = pd.read_html(table)[0]\n",
    "            yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "            yearly_dfs.append(yearly_game_log)\n",
    "        else: pass\n",
    "        '''\n",
    "      \n",
    "        if len(tables)==0:\n",
    "            if year > 1976: continue\n",
    "            else:\n",
    "                aba_url = url + \"/aba/\"\n",
    "                webpage = urlopen(aba_url)\n",
    "                html = BeautifulSoup(webpage)\n",
    "                aba_tables = html.findAll('table')\n",
    "\n",
    "                if len(aba_tables)==0: continue\n",
    "                else: \n",
    "                    table = str(aba_tables[-1])\n",
    "                    yearly_game_log = pd.read_html(table)[0]\n",
    "                    yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "                    yearly_game_log[\"LEAGUE\"] = 'ABA'\n",
    "\n",
    "        else:\n",
    "            table = str(tables[-1])\n",
    "            yearly_game_log = pd.read_html(table)[0]\n",
    "            yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "            yearly_game_log[\"LEAGUE\"] = 'NBA'\n",
    "\n",
    "        yearly_dfs.append(yearly_game_log)        \n",
    "\n",
    "    reg_season_game_logs = pd.concat([x for x in yearly_dfs],ignore_index=True,sort=False)\n",
    "    reg_season_game_logs[\"PLAYOFF\"] = 'N'\n",
    "    reg_season_game_logs['SERIES'] = np.nan\n",
    "\n",
    "    reg_season_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', \n",
    "                                      'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',\n",
    "                                      'Unnamed: 7': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)  \n",
    "    \n",
    "    return reg_season_game_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_playoff_game_logs(player_idx,letter):\n",
    "    \n",
    "    playoff_game_logs = None\n",
    "    \n",
    "    playoff_url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog-playoffs/\"\n",
    "    webpage = urlopen(playoff_url)\n",
    "    html = BeautifulSoup(webpage)\n",
    "    tables = html.findAll('table')\n",
    "    \n",
    "    if len(tables) > 0:\n",
    "        table = str(html.findAll('table')[7])\n",
    "        playoff_game_logs = pd.read_html(table)[0]\n",
    "        playoff_game_logs[\"PLAYOFF\"] = 'Y'\n",
    "        playoff_game_logs[\"AGE\"] = np.nan\n",
    "\n",
    "        playoff_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', 'Series':'SERIES',\n",
    "                                          'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',playoff_game_logs.columns[2]:'DATE',\n",
    "                                          'Unnamed: 8': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)\n",
    "    \n",
    "    return playoff_game_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_career_game_logs(player_data,verbose=True):\n",
    "    \n",
    "    logger = f\"{errorLog}/log.txt\"\n",
    "    \n",
    "    # PLAYER DATA\n",
    "    player_idx = player_data['index']\n",
    "    letter = player_idx[0]\n",
    "    player_name = player_data['Player']\n",
    "    from_yr, to_yr = row[[\"From\",\"To\"]].values\n",
    "\n",
    "    if verbose:\n",
    "        print(player_idx,player_name)\n",
    "    \n",
    "    # GET REGULAR SEASON GAME LOGS\n",
    "    try:\n",
    "        reg_season_game_logs = get_reg_season_game_logs(player_idx,letter,from_yr,to_yr)\n",
    "    except:\n",
    "        reg_season_game_logs = None\n",
    "        with open(logger,\"a\") as logs: \n",
    "            logs.write(f\"{player_idx} , {player_name}, error in regular season game logs \\n\")\n",
    "\n",
    "    # GET PLAYOFF GAME LOGS\n",
    "    try:\n",
    "        playoff_game_logs = get_playoff_game_logs(player_idx,letter)\n",
    "    except:\n",
    "        playoff_game_logs = None\n",
    "        with open(logger,\"a\") as logs: \n",
    "            logs.write(f\"{player_idx} , {player_name}, error in playoff game logs \\n\")\n",
    "            \n",
    "        \n",
    "    \n",
    "    # CONCATENATING REGULAR SEASON AND PLAYOFF GAMES\n",
    "    career_game_logs = pd.concat([reg_season_game_logs,playoff_game_logs],ignore_index=True,sort=False)\n",
    "    career_game_logs['HOME/AWAY'] = career_game_logs['HOME/AWAY'].apply(lambda x: 'AWAY' if x=='@' else 'HOME')\n",
    "    \n",
    "    # FORMAT CAREER GAME LOGS, SORT BY DATE\n",
    "    career_game_logs['Rk'] = career_game_logs['Rk'].astype(str)\n",
    "    career_game_logs = career_game_logs[career_game_logs['Rk'].str.isnumeric().values]\n",
    "    \n",
    "    career_game_logs.rename(columns = {'Series':'SERIES'},inplace=True)\n",
    "    career_game_logs['INDEX'] = player_idx\n",
    "    career_game_logs['NAME']  = player_name\n",
    "    \n",
    "    career_game_logs.sort_values('DATE',inplace=True)\n",
    "    career_game_logs.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "    return career_game_logs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, w = 45, 50\n",
    "player_dfs = []\n",
    "for num,(index, row) in enumerate(df.iloc[k:w].iterrows()):\n",
    "    print(k + num)\n",
    "    \n",
    "    if (num + 1) % 10 == 0:\n",
    "        game_logs = pd.concat([player for player in player_dfs],ignore_index=True,sort=False)\n",
    "        game_logs.to_csv(f\"{finalDataDir}/player_game_logs.csv\",index=False)\n",
    "        print(\"df shape\",game_logs.shape)\n",
    "    \n",
    "    career_game_logs = get_career_game_logs(row)\n",
    "    player_dfs.append(career_game_logs)\n",
    "    \n",
    "    print(career_game_logs.shape)\n",
    "    \n",
    "game_logs = pd.concat([player for player in player_dfs],ignore_index=True,sort=False)\n",
    "print(\"\\n\")\n",
    "print(game_logs.shape)\n",
    "\n",
    "game_logs.to_csv(f\"{finalDataDir}/player_game_logs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs['NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs[game_logs[\"PLAYOFF\"]=='Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 45\n",
    "player_data = df.iloc[k]\n",
    "\n",
    "player_idx = player_data['index']\n",
    "letter = player_idx[0]\n",
    "player_name = player_data['Player']\n",
    "from_yr, to_yr = player_data[[\"From\",\"To\"]].values\n",
    "\n",
    "print(player_name)\n",
    "'''\n",
    "reg = get_reg_season_game_logs(player_idx,letter,from_yr,to_yr)\n",
    "plf = get_playoff_game_logs(player_idx,letter)\n",
    "\n",
    "print(reg.shape)\n",
    "print(plf.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dfs = []\n",
    "for year in range(from_yr, to_yr+1):\n",
    "    url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog/{year}\"\n",
    "    webpage = urlopen(url)\n",
    "    html = BeautifulSoup(webpage)\n",
    "    tables = html.findAll('table')\n",
    "\n",
    "    if len(tables)==0:\n",
    "        if year > 1976: continue\n",
    "        else:\n",
    "            aba_url = url + \"/aba/\"\n",
    "            webpage = urlopen(aba_url)\n",
    "            html = BeautifulSoup(webpage)\n",
    "            aba_tables = html.findAll('table')\n",
    "      \n",
    "            if len(aba_tables)==0: continue\n",
    "            else: \n",
    "                table = str(aba_tables[-1])\n",
    "                yearly_game_log = pd.read_html(table)[0]\n",
    "                yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "                yearly_game_log[\"LEAGUE\"] = 'ABA'\n",
    "                \n",
    "    else:\n",
    "        table = str(tables[-1])\n",
    "        yearly_game_log = pd.read_html(table)[0]\n",
    "        yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "        yearly_game_log[\"LEAGUE\"] = 'NBA'\n",
    "\n",
    "    yearly_dfs.append(yearly_game_log)\n",
    "    print(len(yearly_game_log))\n",
    "\n",
    "\n",
    "reg_season_game_logs = pd.concat([x for x in yearly_dfs],ignore_index=True)\n",
    "reg_season_game_logs[\"PLAYOFF\"] = 'N'\n",
    "reg_season_game_logs['Series'] = np.nan\n",
    "\n",
    "reg_season_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', \n",
    "                                  'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',\n",
    "                                  'Unnamed: 7': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_game_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url,playoff_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPING PLAYOFF GAMES\n",
    "playoff_url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog-playoffs/\"\n",
    "webpage = urlopen(playoff_url)\n",
    "html = BeautifulSoup(webpage)\n",
    "#print(playoff_url)\n",
    "\n",
    "table = str(html.findAll('table')[7])\n",
    "playoff_game_logs = pd.read_html(table)[0]\n",
    "playoff_game_logs[\"PLAYOFF\"] = 'Y'\n",
    "playoff_game_logs[\"AGE\"] = np.nan\n",
    "\n",
    "playoff_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', \n",
    "                                  'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',playoff_game_logs.columns[2]:'DATE',\n",
    "                                  'Unnamed: 8': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)\n",
    "playoff_game_logs = playoff_game_logs[reg_season_game_logs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "row = df.iloc[1]\n",
    "\n",
    "player_idx = row['index']\n",
    "letter = player_idx[0]\n",
    "player_name = row['Player']\n",
    "print(letter,player_idx,player_name)\n",
    "\n",
    "from_yr, to_yr = row[[\"From\",\"To\"]].values\n",
    "yearly_dfs = []\n",
    "\n",
    "# SCRAPING REGULAR SEASON GAMES\n",
    "for year in range(from_yr, to_yr+1):\n",
    "    url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog/{year}\"\n",
    "    webpage = urlopen(url)\n",
    "    html = BeautifulSoup(webpage)\n",
    "    tables = html.findAll('table')\n",
    "    \n",
    "    if len(tables)==0: continue\n",
    "    else:\n",
    "        table = str(tables[-1])\n",
    "        yearly_game_log = pd.read_html(table)[0]\n",
    "        yearly_game_log[\"PLAYOFF\"] = 'N'\n",
    "\n",
    "        yearly_dfs.append(yearly_game_log)\n",
    "        #print(url)\n",
    "\n",
    "\n",
    "reg_season_game_logs = pd.concat([x for x in yearly_dfs],ignore_index=True)\n",
    "reg_season_game_logs[\"PLAYOFF\"] = 'N'\n",
    "reg_season_game_logs['Series'] = np.nan\n",
    "\n",
    "reg_season_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', \n",
    "                                  'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',\n",
    "                                  'Unnamed: 7': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)    \n",
    "\n",
    "# SCRAPING PLAYOFF GAMES\n",
    "playoff_url = f\"https://www.basketball-reference.com/players/{letter}/{player_idx}/gamelog-playoffs/\"\n",
    "webpage = urlopen(playoff_url)\n",
    "html = BeautifulSoup(webpage)\n",
    "#print(playoff_url)\n",
    "\n",
    "table = str(html.findAll('table')[7])\n",
    "playoff_game_logs = pd.read_html(table)[0]\n",
    "playoff_game_logs[\"PLAYOFF\"] = 'Y'\n",
    "playoff_game_logs[\"AGE\"] = np.nan\n",
    "\n",
    "playoff_game_logs.rename(columns = {'Date': 'DATE', 'Age': 'AGE', 'Tm': 'TEAM', \n",
    "                                  'Unnamed: 5': 'HOME/AWAY', 'Opp': 'OPPONENT',playoff_game_logs.columns[2]:'DATE',\n",
    "                                  'Unnamed: 8': 'RESULT', 'GmSc': 'GAME_SCORE'}, inplace=True)\n",
    "playoff_game_logs = playoff_game_logs[reg_season_game_logs.columns]\n",
    "\n",
    "# CONCATENATING REGULAR SEASON AND PLAYOFF GAMES\n",
    "career_game_logs = pd.concat([reg_season_game_logs,playoff_game_logs],ignore_index=True)\n",
    "career_game_logs['HOME/AWAY'] = career_game_logs['HOME/AWAY'].apply(lambda x: 'AWAY' if x=='@' else 'HOME')\n",
    "\n",
    "# FORMAT CAREER GAME LOGS, SORT BY DATE\n",
    "career_game_logs['Rk'] = career_game_logs['Rk'].astype(str)\n",
    "career_game_logs = career_game_logs[career_game_logs['Rk'].str.isnumeric().values]\n",
    "\n",
    "career_game_logs.rename(columns = {'Series':'SERIES'},inplace=True)\n",
    "career_game_logs['INDEX'] = player_idx\n",
    "career_game_logs['NAME']  = player_name\n",
    "\n",
    "career_game_logs.sort_values('DATE',inplace=True)\n",
    "career_game_logs.reset_index(drop=True,inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_env",
   "language": "python",
   "name": "nba_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
